---
title: "Report: MovieLens Project"
author: "FH"
date: "August 3, 2020"
output: html_document
--output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Inroduction

The original "movielens"(20M) data set was generated by the GroupLens research lab and can be found here https://grouplens.org/datasets/movielens/20m/ 
The edx (10M) data is a subset of the "movielens" data" (10M) is inscluded in the *dslabs* package. For the evaluation of the recommendation algorithm. 
a "validation" data set was generated.  The "validation" data set will be only used to test the final algorithm and contains only 10% of "movielens". 
The "edx" data set that contains 9,000,055 observations and 6 variables represented in 6 total columns. Each row represents one user giving one rating to one specific movie. In total no zero ratings were given. There are 69878 unique users and 10677 movies in the edx data set.

str(edx)

#How many different users are in the edx dataset?
edx %>%
  summarize(n_users = n_distinct(userId),
            n_movies = n_distinct(movieId))
            
No missing values are present in the edx
#Check missing values
sum(is.na(edx))

```{r edx, echo=TRUE}
head(edx, 5)
```

The edx data consists of following variables:

-*"movieId"* is a numerical variable denotes id's for each movie starts with 1 to 163949. 
-*"title"* is a string varible describing the title of a movie.

-*"year"* mumerical variable with the year of movie release from 1902 to 2016.

-*"genres"* is a categorical variable that represent 17 different genres 

-*"userId"* a numerical variable to idenfy unique users.

-*"rating"* a numerical variable from 0 to 5.

-*"timestamp"* represents time when rating was given in seconds since January 1, 1970 

# Data exploration and data processing

Several steps before using the data for visualization: 

#Sort data by movieId 
edx<-arrange(edx, by=movieId)

# Split title and year into separate columns
edx<-extract(edx, title, c("title", "release_year"), "(.*)\\((\\d{4})\\)$")

# Convert year character into to an integer
edx<-transform(edx, release_year = as.numeric(release_year))

#Split genres into single columns per genre
edx<-edx %>% separate_rows(genres, sep = "\\|")

#Transform the rating timestamp to datetime year
edx<-transform(edx, rating_time = round_date(as_datetime(timestamp), unit="month"))
  
#Check missing values
sum(is.na(edx))

head(edx,10)

#How many zeros were given as ratings in the edx dataset?
sum(edx$rating==0)
edx %>% filter(rating == 0) %>% tally()

#How many different users and movies are in the edx dataset?
edx %>%
  summarize(n_users = n_distinct(userId),
            n_movies = n_distinct(movieId))

#Number of movies in different genres
edx%>%group_by(genres) %>%
  summarize(count = n()) 
edx

# Number of different genres
edx%>%summarize(genre = n_distinct(genres))
edx

#How many movie ratings are in each of the following genres in the edx dataset?
edx %>% group_by(genres) %>%
  summarize(count = n()) %>%
  arrange(desc(count))
edx

# Top 10 of movies with greatest number of ratings?
edx%>%group_by(movieId)%>%mutate(count=n())%>%top_n(5)%>%arrange(desc(count()))
#or

edx %>% group_by(movieId, title) %>%
  summarize(count = n()) %>%
  arrange(desc(count))

The
Descriptive statistics
Is there any outliers? 
What is the correlation between the variables? 
Boxplot 
Frequency



```{r pressure, echo=FALSE}
plot(pressure)
```


## Method Section

The "edx" data set will be split into a training set and the test set.

# Generate training and test sets
set.seed(107)
test_index <- createDataPartition(y=edx$ratings, times = 1, p = 0.5, list = FALSE)
test_set <- edx[test_index, ]
train_set <- edx[-test_index, ]  

Develop your algorithm using the edx set. For a final test of your algorithm, predict movie ratings in the validation set (the final hold-out test set) as if they were unknown. RMSE will be used to evaluate how close your predictions are to the true values in the validation set (the final hold-out test set).

Important: The validation data (the final hold-out test set) should NOT be used for training your algorithm and should ONLY be used for evaluating the RMSE of your final algorithm. You should split the edx data into separate training and test sets to design and test your algorithm.



Explain the method and techniques used, Visualization with insights, data exploration. Use at least two Methods 
You will use the following code to generate your datasets. Develop your algorithm using the edx set. For a final test of your algorithm, predict movie ratings in the validation set (the final hold-out test set) as if they were unknown. RMSE will be used to evaluate how close your predictions are to the true values in the validation set (the final hold-out test set).

Prediction Performance
RMSE in validation data set >90?

## Results Section

Resultes presented and discussed.Model performance. 


## Conclusion Section

Brief summary of the report. It's limitation and future work.

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
